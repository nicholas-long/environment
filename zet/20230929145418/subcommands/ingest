#!/usr/bin/awk -f

# environ var fsdb_prog holds original arg var $0, the main program
BEGIN {
  timestamps = ENVIRON["timestamps"]
  if (timestamps) OFS = "\t" # use tab char to separate timestamp from line
  compress_line_limit = 100 # constant value
  for(n=0;n<256;n++) ord[sprintf("%c",n)]=n # prepare char code lookup table
  partcount = ENVIRON["partitions"]
  print "using", partcount, "partitions"
  hasingesthook = (system("test -e hooks/ingest") == 0)
  # populate initial counts of parition file lines
  for (n = 0; n < partcount; n++) {
    cmd = "wc -l data/" n " 2>/dev/null"
    cmd | getline
    partdumpsize[n] = $1
    close(cmd)
  }
}
{
  # calculate hashcode
  hashcode = 0
  for (n = 1; n <= length($1); n++) hashcode += n * ord[substr($1,n,1)]
  part = hashcode % partcount # partition number
  partfn = "data/" part # generate filename
  if (timestamps) { # print timestamps before lines if enabled
    print systime(), $0 >> partfn
  } else {
    print >> partfn
  }
  # maintain mru most recent use collection for file handles
  mru[partfn] = NR
  if (++lines_written[part] > compress_line_limit) {
    close(partfn)
    delete mru[partfn]
    # call compress subcommand here
    #print "compressing", part, "total read", NR
    # printing too much will slow it way down
    compresscommand = ENVIRON["fsdb_prog"] " compress " part
    system(compresscommand)
    lines_written[part] = 0
  }
  # clean up stuff from MRU if it is too big
  if (length(mru) > 64) {
    oldest = 0
    for (p in mru) if (mru[p] < oldest) oldest = mru[p]
    for (p in mru) if (mru[p] == oldest) {
      close(p)
      delete mru[p]
    }
  }
  # TODO: print to ingest hook if it exists: var hasingesthook
}
# NR % 1000000 == 0 { print "total records", NR }
